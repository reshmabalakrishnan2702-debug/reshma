# -*- coding: utf-8 -*-
"""im_project_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YdPR1YZfUgjR4P2u-BpGlLt00NdPrvMF
"""

import pandas as pd
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")

from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.metrics import (
    f1_score, accuracy_score, classification_report,
    roc_auc_score, confusion_matrix
)
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

from packaging import version
import sklearn

# --- Install boosted models ---
!pip -q install xgboost lightgbm
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

TARGET  = "is_promoted"
ID_COL  = "employee_id"

RANDOM_STATE = 42

#Load train, test, sample submission

train = pd.read_csv("/content/train_LZdllcl.csv")
test  = pd.read_csv("/content/test_2umaH9m.csv")
sample_sub = pd.read_csv("/content/sample_submission_M0L0uXE.csv")

X = train.drop(columns=[TARGET])
y = train[TARGET].astype(int)

if ID_COL in X.columns:
    X = X.drop(columns=[ID_COL])
X_test_raw = test.drop(columns=[ID_COL])

num_cols = X.select_dtypes(include=[np.number]).columns.tolist()
cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()

print("Train shape:", train.shape)
print("Test shape :", test.shape)

#  # =========================================
# 2) FULL EDA (plots + summaries)
# =========================================

# 2.1 Overview
print("Train shape:", train.shape)
print("Test shape :", test.shape)
print("\nDtypes:\n", train.dtypes)
print("\nHead:\n", train.head())

# 2.2 Missing values (table + barplot)
missing = train.isnull().sum().sort_values(ascending=False)
missing = missing[missing > 0]
if not missing.empty:
    print("\nMissing values:\n", missing)
    plt.figure(figsize=(8,4))
    missing.plot(kind="barh", title="Missing values per column")
    plt.xlabel("Count")
    plt.tight_layout()
    plt.show()

# 2.3 Target distribution (counts + % + plot)
plt.figure(figsize=(4,3))
sns.countplot(x=TARGET, data=train)
plt.title("Target distribution (is_promoted)")
plt.tight_layout()
plt.show()
print("\nTarget counts:\n", train[TARGET].value_counts())
print("\nTarget ratio:\n", train[TARGET].value_counts(normalize=True))

# 2.4 Numeric feature distributions (histograms + boxplots vs target)
if len(num_cols) > 0:
    train[num_cols].hist(bins=20, figsize=(15,10))
    plt.suptitle("Numeric Feature Distributions (Histograms)", y=1.02)
    plt.tight_layout()
    plt.show()

    for col in num_cols[:6]:  # limit to first 6 for readability
        plt.figure(figsize=(5,3))
        sns.boxplot(x=TARGET, y=col, data=train)
        plt.title(f"{col} vs {TARGET}")
        plt.tight_layout()
        plt.show()

# 2.5 Categorical feature distributions (barplots top categories)
for col in cat_cols[:6]:  # show top 6 categorical
    plt.figure(figsize=(6,3))
    (train[col].value_counts(normalize=True)
         .head(10)
         .plot(kind="bar", title=f"Top categories: {col}"))
    plt.ylabel("Proportion")
    plt.tight_layout()
    plt.show()

# 2.6 Correlation heatmap (numeric + target, with VALUES)
if len(num_cols) > 0:
    corr = train[num_cols + [TARGET]].corr()
    plt.figure(figsize=(12,10))
    sns.heatmap(
        corr, annot=True, fmt=".2f",
        cmap="coolwarm", center=0, cbar=True, square=True
    )
    plt.title("Correlation Heatmap (numeric features + target)")
    plt.tight_layout()
    plt.show()
    print("\nCorrelation with target:\n", corr[TARGET].sort_values(ascending=False))

# 2.7 Outlier diagnostics (IQR rule + boxplots)
def iqr_outlier_report(df, cols):
    rows, n = [], len(df)
    for c in cols:
        x = pd.to_numeric(df[c], errors="coerce")
        q1, q3 = np.nanpercentile(x, [25, 75])
        iqr = q3 - q1
        lo, up = q1 - 1.5*iqr, q3 + 1.5*iqr
        cnt = ((x < lo) | (x > up)).sum()
        rows.append({"column": c, "outlier_count": int(cnt), "outlier_%": 100*cnt/n})
    return pd.DataFrame(rows).sort_values("outlier_%", ascending=False)

if len(num_cols) > 0:
    outlier_df = iqr_outlier_report(train, num_cols)
    print("\nOutlier report (IQR rule):\n", outlier_df.head(10))

    for col in outlier_df.head(3)["column"]:
        plt.figure(figsize=(6,3))
        sns.boxplot(x=train[col])
        plt.title(f"Boxplot with outliers: {col}")
        plt.tight_layout()
        plt.show()

#Preprocessing (outliers + missing + scale + encode)

class SimplePercentileCapper(BaseEstimator, TransformerMixin):
    def __init__(self, columns=None, lower_q=0.01, upper_q=0.99):
        self.columns = columns; self.lower_q=lower_q; self.upper_q=upper_q; self.bounds_={}
    def fit(self, X, y=None):
        X_ = pd.DataFrame(X)
        for c in (self.columns or X_.columns):
            x = pd.to_numeric(X_[c], errors="coerce")
            lo, up = np.nanquantile(x, self.lower_q), np.nanquantile(x, self.upper_q)
            self.bounds_[c] = (lo, up)
        return self
    def transform(self, X):
        X_ = pd.DataFrame(X).copy()
        for c,(lo,up) in self.bounds_.items():
            if c in X_.columns:
                X_[c] = np.clip(pd.to_numeric(X_[c], errors="coerce"), lo, up)
        return X_

enc_kwargs = {"handle_unknown": "ignore"}
if version.parse(sklearn.__version__) < version.parse("1.2"):
    enc_kwargs["sparse"] = True

numeric = Pipeline([
    ("cap", SimplePercentileCapper(columns=num_cols)),
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler(with_mean=False))
])
categorical = Pipeline([
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("onehot", OneHotEncoder(**enc_kwargs))
])
preprocess = ColumnTransformer([
    ("num", numeric, num_cols),
    ("cat", categorical, cat_cols)
])

#Model Leaderboard (LogReg, RF, XGB, LGBM)

pos, neg = (y==1).sum(), (y==0).sum()
scale_pos_weight = neg / max(pos,1)
print("scale_pos_weight:", scale_pos_weight)

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)

models = {
    "LogReg": Pipeline([
        ("prep", preprocess),
        ("clf", LogisticRegression(max_iter=2000, class_weight="balanced", solver="lbfgs", random_state=RANDOM_STATE))
    ]),
    "RandomForest": Pipeline([
        ("prep", preprocess),
        ("clf", RandomForestClassifier(
            n_estimators=500, class_weight="balanced_subsample", random_state=RANDOM_STATE))
    ]),
    "XGBoost": Pipeline([
        ("prep", preprocess),
        ("clf", XGBClassifier(
            n_estimators=700, learning_rate=0.05, max_depth=6,
            subsample=0.8, colsample_bytree=0.8, reg_lambda=1.0,
            scale_pos_weight=scale_pos_weight,
            tree_method="hist", eval_metric="logloss", random_state=RANDOM_STATE, n_jobs=0))
    ]),
    "LightGBM": Pipeline([
        ("prep", preprocess),
        ("clf", LGBMClassifier(
            n_estimators=1200, learning_rate=0.03, num_leaves=63,
            subsample=0.8, colsample_bytree=0.8, reg_lambda=1.0,
            scale_pos_weight=scale_pos_weight, random_state=RANDOM_STATE))
    ])
}

rows = []
for name, pipe in models.items():
    f1  = cross_val_score(pipe, X, y, cv=cv, scoring="f1_macro")
    acc = cross_val_score(pipe, X, y, cv=cv, scoring="accuracy")
    rows.append({"Model": name, "F1_macro": f1.mean(), "Acc": acc.mean()})

leaderboard = pd.DataFrame(rows).sort_values("F1_macro", ascending=False).reset_index(drop=True)
print("=== CV Leaderboard ===")
print(leaderboard)

best_name = leaderboard.loc[0,"Model"]
best_model = models[best_name]
print("Best model selected:", best_name)

#Threshold tuning (on hold-out)

X_tr, X_va, y_tr, y_va = train_test_split(X,y,test_size=0.2,random_state=RANDOM_STATE,stratify=y)
best_model.fit(X_tr,y_tr)
proba = best_model.predict_proba(X_va)[:,1]

best_t, best_f1 = 0.5,-1
for t in np.linspace(0.2,0.8,25):
    pred=(proba>=t).astype(int)
    f1=f1_score(y_va,pred,average="macro")
    if f1>best_f1:
        best_t, best_f1 = t,f1
print(f"Best threshold={best_t:.3f}, F1_macro={best_f1:.4f}")

#Train on full data + Final Submission

best_model.fit(X,y)
test_proba = best_model.predict_proba(X_test_raw)[:,1]
test_pred  = (test_proba>=best_t).astype(int)

final_sub = sample_sub.copy()
final_sub = final_sub[[ID_COL,TARGET]]
final_sub[TARGET] = test_pred
final_sub.to_csv("final_submission1.csv", index=False)
print("Saved final_submission1.csv using", best_name)
print(final_sub.sample(5))

print(final_sub.sample(10))

from google.colab import files
files.download("final_submission1.csv")